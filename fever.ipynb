{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEVER: Fact Extraction and VERification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import fever\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalities of Oracle Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = 'data/single/fever.db'\n",
    "MAT_PATH = 'data/index/tfidf-count-ngram=1-hash=16777216.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = fever.Oracle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Tetris has sold millions of physical copies.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tetris',\n",
       " 'Jolin_Tsai_discography',\n",
       " 'List_of_best-selling_Game_Boy_video_games',\n",
       " 'Eminem_discography']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.closest_docs(query, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Tetris -LRB- , pronounced -LSB- ˈtɛtrʲɪs -RSB- -RRB- is a tile-matching puzzle video game , originally designed and programmed by Russian game designer Alexey Pajitnov . It was released on June 6 , 1984 , while he was working for the Dorodnitsyn Computing Centre of the Academy of Science of the USSR in Moscow . He derived its name from the Greek numerical prefix tetra - -LRB- all of the game 's pieces contain four segments -RRB- and tennis , Pajitnov 's favorite sport .   Tetris was the first entertainment software to be exported from the USSR to the US , where it was published by Spectrum HoloByte for Commodore 64 and IBM PC . The Tetris game is a popular use of tetrominoes , the four-element special case of polyominoes . Polyominoes have been used in popular puzzles since at least 1907 , and the name was given by the mathematician Solomon W. Golomb in 1953 . However , even the enumeration of pentominoes is dated to antiquity .   The game -LRB- or one of its many variants -RRB- is available for nearly every video game console and computer operating system , as well as on devices such as graphing calculators , mobile phones , portable media players , PDAs , Network music players and even as an Easter egg on non-media products like oscilloscopes . It has even inspired Tetris serving dishes and been played on the sides of various buildings .   While versions of Tetris were sold for a range of 1980s home computer platforms as well as arcades , it was the hugely successful handheld version for the Game Boy launched in 1989 that established the game as one of the most popular ever . Electronic Gaming Monthly '' 's 100th issue had Tetris in first place as `` Greatest Game of All Time '' . In 2007 , Tetris came in second place in IGN 's `` 100 Greatest Video Games of All Time '' . In January 2010 , it was announced that the Tetris franchise had sold more than 170 million copies , approximately 70 million physical copies and over 100 million copies for cell phones , making it the best selling paid-downloaded game of all time . On 14 March 2014 , The Tetris Company announced a deal to bring Tetris '' to two of the latest hardware platforms , the Xbox One and PlayStation 4 , in partnership with Ubisoft -LRB- publishing -RRB- and SoMa Play -LRB- development -RRB- , to coincide with the franchise 's 30th anniversary . \"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.doc_ids2texts(['Tetris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tetris -LRB- , pronounced -LSB- ˈtɛtrʲɪs -RSB- -RRB- is a tile-matching puzzle video game , originally designed and programmed by Russian game designer Alexey Pajitnov .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.get_sentence('Tetris', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Jolin_Tsai_discography',\n",
       "  9): 'Her next release under Sony , Magic -LRB- 2003 -RRB- , was heralded as her comeback album , which sold more than 1.5 million copies in Asia , with more than 360,000 copies sold in Taiwan alone , and the album made her the best-selling female singer of the year in Taiwan .',\n",
       " ('Jolin_Tsai_discography',\n",
       "  11): 'The album has sold over 2 million copies in Asia , with 300,000 copies sold in Taiwan alone , and made her the best-selling female singer of the year in Taiwan .',\n",
       " ('Tetris',\n",
       "  12): 'In January 2010 , it was announced that the Tetris franchise had sold more than 170 million copies , approximately 70 million physical copies and over 100 million copies for cell phones , making it the best selling paid-downloaded game of all time .'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.choose_sents_from_doc_ids(query, oracle.closest_docs(query, k=4), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Jolin_Tsai_discography',\n",
       "  9): 'Her next release under Sony , Magic -LRB- 2003 -RRB- , was heralded as her comeback album , which sold more than 1.5 million copies in Asia , with more than 360,000 copies sold in Taiwan alone , and the album made her the best-selling female singer of the year in Taiwan .',\n",
       " ('Jolin_Tsai_discography',\n",
       "  11): 'The album has sold over 2 million copies in Asia , with 300,000 copies sold in Taiwan alone , and made her the best-selling female singer of the year in Taiwan .',\n",
       " ('Tetris',\n",
       "  12): 'In January 2010 , it was announced that the Tetris franchise had sold more than 170 million copies , approximately 70 million physical copies and over 100 million copies for cell phones , making it the best selling paid-downloaded game of all time .'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.read(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_iterator = iter(fever.TrainReader().read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_ex = next(fever_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
      "VERIFIABLE\n",
      "SUPPORTS\n"
     ]
    }
   ],
   "source": [
    "print(fever_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FEVER Example({'id': 75397, 'verifiable': 'VERIFIABLE', 'label': 'SUPPORTS', 'claim': 'Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.', 'evidence': [[[92206, 104971, 'Nikolaj_Coster-Waldau', 7], [92206, 104971, 'Fox_Broadcasting_Company', 0]]]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nikolaj_Coster-Waldau', 7), ('Fox_Broadcasting_Company', 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_ex.get_evidence_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_labels = pd.Series(\n",
    "    [ex.label for ex in fever.TrainReader().read()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUPPORTS           80035\n",
       "NOT ENOUGH INFO    35639\n",
       "REFUTES            29775\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_labels = pd.Series(\n",
    "    [ex.label for ex in fever.DevReader().read()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT ENOUGH INFO    3333\n",
       "SUPPORTS           3333\n",
       "REFUTES            3333\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Document Retrieval and Sentence Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7335examples [25:53,  4.72examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 1, accuracy 1283/5524 = 0.23225923244026067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  99%|█████████▊| 7261/7362 [24:51<00:20,  4.87examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 3, accuracy 2491/5469 = 0.4554763210824648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 100%|█████████▉| 7269/7289 [25:29<00:04,  4.75examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 5, accuracy 3131/5503 = 0.5689623841540977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7236examples [25:27,  4.74examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 10, accuracy 3783/5486 = 0.6895734597156398\n"
     ]
    }
   ],
   "source": [
    "for num_docs in [1,3,5,10]:\n",
    "    fever.doc_retrieval_accuracy(reader=fever.TrainReader(samp_percentage=0.05),\n",
    "                                oracle=oracle,\n",
    "                                num_docs=num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7360examples [05:09, 23.81examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 1, accuracy 2810/5492 = 0.5116533139111434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7382examples [05:07, 23.99examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 3, accuracy 3727/5561 = 0.6702032008631541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7229examples [04:59, 24.16examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 5, accuracy 3941/5424 = 0.7265855457227138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7358examples [05:04, 24.13examples/s]                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 10, accuracy 4511/5514 = 0.8180993833877402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for num_sents in [1,3,5,10]:\n",
    "    fever.sentence_selection_accuracy(reader=fever.TrainReader(samp_percentage=0.05),\n",
    "                                oracle=oracle,\n",
    "                                num_sents=num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 100%|█████████▉| 7235/7241 [31:58<00:01,  3.77examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 1, accuracy 1195/5414 = 0.22072404876246768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7346examples [28:28,  4.30examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 3, accuracy 2572/5564 = 0.46225736879942486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  98%|█████████▊| 7262/7373 [28:24<00:26,  4.26examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 5, accuracy 3128/5527 = 0.5659489777456125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  98%|█████████▊| 7221/7338 [27:09<00:26,  4.43examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 10, accuracy 3776/5482 = 0.6887997081357169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for num_docs in [1,3,5,10]:\n",
    "    fever.doc_retrieval_accuracy(reader=fever.TrainReader(samp_percentage=0.05),\n",
    "                                oracle=oracle,\n",
    "                                num_docs=num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7384examples [05:10, 23.76examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 1, accuracy 2845/5512 = 0.5161465892597968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  97%|█████████▋| 7216/7446 [05:00<00:09, 23.99examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 3, accuracy 3605/5400 = 0.6675925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7232examples [04:59, 24.15examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 5, accuracy 4012/5391 = 0.7442033017992952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  99%|█████████▉| 7239/7285 [05:11<00:01, 23.23examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 10, accuracy 4436/5467 = 0.8114139381745016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for num_sents in [1,3,5,10]:\n",
    "    fever.sentence_selection_accuracy(reader=fever.TrainReader(samp_percentage=0.05),\n",
    "                                oracle=oracle,\n",
    "                                num_sents=num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling for NotEnoughInfo class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_for_NEI(oracle, num_docs=5, num_sents=5):\n",
    "    names = ['training','dev','test']\n",
    "    for name in names:\n",
    "        print('Working on {} split'.format(name))\n",
    "        original_path = 'data/fever-data/{}.jsonl'.format(name)\n",
    "        sampling_path = 'data/fever-data/{}_sampled.jsonl'.format(name)\n",
    "        with open(original_path, \"r\") as f:\n",
    "            with open(sampling_path, \"w+\") as f2:\n",
    "                for line in tqdm(f.readlines()):\n",
    "                    line = json.loads(line)\n",
    "\n",
    "                    if name == 'dev' or name == 'test' or line[\"label\"] == \"NOT ENOUGH INFO\":\n",
    "                        evidences = oracle.read(line['claim'], num_docs=num_docs, num_sents=num_sents).keys()\n",
    "                        line['evidence'] = [[[0,0,ev[0],ev[1]] for ev in evidences]]\n",
    "\n",
    "                    f2.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dev split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [1:18:30<00:00,  2.12it/s]\n",
      "  0%|          | 0/9999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [1:14:08<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "sampling_for_NEI(oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RTE Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_overlap_phi(claim, evidence):    \n",
    "    \"\"\"Basis for features for the words in both the premise and hypothesis.\n",
    "    This tends to produce very sparse representations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    claim : a string\n",
    "    evidence : a list of sentences\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    defaultdict\n",
    "       Maps each word in both claim and evidence to 1.\n",
    "    \n",
    "    \"\"\"\n",
    "    sents=[]\n",
    "    for sent in evidence:\n",
    "        sents.extend(utils.process_sent(sent))\n",
    "    overlap = set([w1 for w1 in utils.process_text(claim) if w1 in sents])\n",
    "    return Counter(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):    \n",
    "    \"\"\"Wrapper for `sklearn.linear.model.LogisticRegression`. This is also \n",
    "    called a Maximum Entropy (MaxEnt) Classifier, which is more fitting \n",
    "    for the multiclass case.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear.model.LogisticRegression\n",
    "        A trained `LogisticRegression` instance.\n",
    "    \n",
    "    \"\"\"\n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  98%|█████████▊| 2885/2949 [00:33<00:00, 85.58examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = fever.build_dataset(fever.SampledTrainReader(samp_percentage=percentage), \n",
    "                              word_overlap_phi, oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  98%|█████████▊| 14288/14586 [03:02<00:03, 78.15examples/s]\n",
      "Reading from dataset: 1070examples [00:38, 28.13examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.337     0.176     0.232       357\n",
      "        REFUTES      0.406     0.037     0.068       351\n",
      "       SUPPORTS      0.342     0.804     0.480       362\n",
      "\n",
      "    avg / total      0.361     0.343     0.262      1070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(samp_percentage=percentage), \n",
    "    phi=word_overlap_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_classifier,\n",
    "    assess_reader=fever.SampledDevReader(),\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cross_product_phi(claim, evidence):\n",
    "    \"\"\"Basis for cross-product features. This tends to produce pretty \n",
    "    dense representations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    claim : a string\n",
    "    evidence : a list of sentences\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    defaultdict\n",
    "        Maps each (w1, w2) in the cross-product of words in claim and \n",
    "        evidence to its count. This is a multi-set cross-product\n",
    "        (repetitions matter).\n",
    "    \n",
    "    \"\"\"\n",
    "    sents=[]\n",
    "    for sent in evidence:\n",
    "        sents.extend(utils.process_sent(sent))\n",
    "    return Counter([(w1, w2) for w1, w2 in product(utils.process_text(claim), sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 14595examples [03:05, 78.76examples/s]                     \n",
      "Reading from dataset: 1036examples [00:40, 25.58examples/s]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.336     0.351     0.343       342\n",
      "        REFUTES      0.465     0.244     0.320       328\n",
      "       SUPPORTS      0.394     0.546     0.458       366\n",
      "\n",
      "    avg / total      0.398     0.386     0.377      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(samp_percentage=percentage), \n",
    "    phi=word_cross_product_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_classifier,\n",
    "    assess_reader=fever.SampledDevReader(),\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_with_crossvalidation(X, y):\n",
    "    \"\"\"A MaxEnt model of dataset with hyperparameter cross-validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.   \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear_model.LogisticRegression\n",
    "        A trained model instance, the best model found.\n",
    "    \n",
    "    \"\"\"    \n",
    "    basemod = LogisticRegression(fit_intercept=True)\n",
    "    cv = 3\n",
    "    param_grid = {'C': [0.4, 0.6, 0.8, 1.0],\n",
    "                  'penalty': ['l1','l2']}    \n",
    "    return fever.fit_classifier_with_crossvalidation(X, y, basemod, cv, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 100%|██████████| 145449/145449 [24:46<00:00, 97.85examples/s]\n",
      "Reading from dataset: 100%|██████████| 9999/9999 [05:46<00:00, 28.87examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 1.0, 'penalty': 'l2'}\n",
      "Best score: 0.430\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.362     0.326     0.343      3333\n",
      "        REFUTES      0.426     0.012     0.023      3333\n",
      "       SUPPORTS      0.337     0.698     0.455      3333\n",
      "\n",
      "    avg / total      0.375     0.346     0.274      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(), \n",
    "    phi=word_overlap_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_with_crossvalidation,\n",
    "    assess_reader=fever.SampledDevReader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 29153examples [05:16, 92.02examples/s]                     \n",
      "Reading from dataset: 100%|██████████| 9999/9999 [06:15<00:00, 26.61examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 1.0, 'penalty': 'l1'}\n",
      "Best score: 0.612\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.349     0.527     0.420      3333\n",
      "        REFUTES      0.535     0.219     0.311      3333\n",
      "       SUPPORTS      0.378     0.410     0.394      3333\n",
      "\n",
      "    avg / total      0.421     0.385     0.375      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(samp_percentage=percentage), \n",
    "    phi=word_cross_product_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_with_crossvalidation,\n",
    "    assess_reader=fever.SampledDevReader(),\n",
    "    random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
